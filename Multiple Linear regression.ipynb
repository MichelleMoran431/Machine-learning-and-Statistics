{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b46b1cb9-64e5-4512-a677-9b325a99fd12",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression ##\n",
    "\n",
    "- more than 2 variables \n",
    "\n",
    "The major difference between linear and multiple lies in the evaluation .\n",
    "\n",
    "You can use it to find out which factor has the highest impact on the predicted output and how difference variables relate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431eacea-6814-4d89-8d65-ce51b22dc17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Importing the Libraries\n",
    "The following script imports the necessary libraries:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c4f96-b1bc-4036-9883-8d88c43ff0fd",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Dataset ##\n",
    "\n",
    "The dataset for this example is available at:\n",
    "\n",
    "https://drive.google.com/open?id=1mVmGNx6cbfvRHC_DvF12ZL3wGLSHD9f_\n",
    "\n",
    "Example looks at multiple linear regression to predict the gas consumptions in 48 US states based upon gas taxes , per capita income , paved highways  and the proportion of population that has a drivers licence. \n",
    "\n",
    "The following command imports the dataset from the file you downloaded via the link above:\n",
    "\n",
    "dataset = pd.read_csv('D:\\Datasets\\petrol_consumption.csv')\n",
    "Just like last time, let's take a look at what our dataset actually looks like. Execute the head() command:\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "To see statistical details of the dataset, we'll use the describe() command again:\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f36a7-284d-4365-a549-f471734cc76c",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data ##\n",
    "The next step is to divide the data into attributes and labels as we did previously. However, unlike last time, this time around we are going to use column names for creating an attribute set and label. Execute the following script:\n",
    "\n",
    "X = dataset[['Petrol_tax', 'Average_income', 'Paved_Highways',\n",
    "       'Population_Driver_licence(%)']]\n",
    "y = dataset['Petrol_Consumption']\n",
    "Execute the following code to divide our data into training and test sets:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a64f4-809c-4622-a23e-a3d58225615a",
   "metadata": {},
   "source": [
    "## 4. Training the Algorithm##\n",
    "And finally, to train the algorithm we execute the same code as before, using the fit() method of the LinearRegression class:\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "As said earlier, in case of multivariable linear regression, the regression model has to find the most optimal coefficients for all the attributes. To see what coefficients our regression model has chosen, execute the following script:\n",
    "\n",
    "coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e4ea2-91bc-4f41-b52b-bceebe24ef1d",
   "metadata": {},
   "source": [
    "The result should look something like this:\n",
    "\n",
    "Coefficient\n",
    "Petrol_tax\t-24.196784\n",
    "Average_income\t-0.81680\n",
    "Paved_Highways\t-0.000522\n",
    "Population_Driver_license(%)\t1324.675464\n",
    "This means that for a unit increase in \"petrol_tax\", there is a decrease of 24.19 million gallons in gas consumption. Similarly, a unit increase in proportion of population with a drivers license results in an increase of 1.324 billion gallons of gas consumption. We can see that \"Average_income\" and \"Paved_Highways\" have a very little effect on the gas consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4799d-bd7e-4acf-bddb-6997eb8bcd15",
   "metadata": {},
   "source": [
    "## 5. Making Predictions ##\n",
    "y_pred = regressor.predict(X_test)\n",
    "To compare the actual output values for X_test with the predicted values, execute the following script:\n",
    "\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df\n",
    "The output looks like this:\n",
    "\n",
    "Actual\tPredicted\n",
    "36\t640\t643.176639\n",
    "22\t464\t411.950913\n",
    "20\t649\t683.712762\n",
    "38\t648\t728.049522\n",
    "18\t865\t755.473801\n",
    "1\t524\t559.135132\n",
    "44\t782\t671.916474\n",
    "21\t540\t550.633557\n",
    "16\t603\t594.425464\n",
    "45\t510\t525.038883\n",
    "Evaluating the Algorithm\n",
    "The final step is to evaluate the performance of algorithm. We'll do this by finding the values for MAE, MSE and RMSE. Execute the following script:\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "The output will look similar to this:\n",
    "\n",
    "Mean Absolute Error: 45.8979842541\n",
    "Mean Squared Error: 3609.37119141\n",
    "Root Mean Squared Error: 60.0780425065\n",
    "You can see that the value of root mean squared error is 60.07, which is slightly greater than 10% of the mean value of the gas consumption in all states. This means that our algorithm was not very accurate but can still make reasonably good predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c3020-d3de-4132-a9c0-967096bf0b21",
   "metadata": {},
   "source": [
    "## Factors affecting inaccuracy ##\n",
    "There are many factors that may have contributed to this inaccuracy, a few of which are listed here:\n",
    "\n",
    "Need more data: Only one year worth of data isn't that much, whereas having multiple years worth could have helped us improve the accuracy quite a bit.\n",
    "Bad assumptions: We made the assumption that this data has a linear relationship, but that might not be the case. Visualizing the data may help you determine that.\n",
    "Poor features: The features we used may not have had a high enough correlation to the values we were trying to predict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b94cf-358d-47bf-9440-27302cd77995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a126502-c68b-44b0-8c54-dea6ca2c695a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
